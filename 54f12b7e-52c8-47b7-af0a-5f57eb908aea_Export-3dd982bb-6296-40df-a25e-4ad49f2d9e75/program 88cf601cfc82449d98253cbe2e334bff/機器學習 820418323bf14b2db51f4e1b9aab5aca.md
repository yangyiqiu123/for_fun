# 機器學習

使用Pillow中的Image函式庫讀取圖片，得到的是一個PIL（Python Imaging Library）影像物件，可以使用numpy的array方法將其轉換為numpy陣列，得到的形狀是(height, width, channels)。

而使用OpenCV讀取圖片，得到的是一個numpy陣列，形狀是(height, width, channels)，其通道的順序是BGR而非Pillow的RGB，需要注意。

1. 壓縮圖片：您可以將所有圖片壓縮成一個 zip 檔案，然後再上傳到 Colab。這樣做可以減少單個圖片的大小，從而提高上傳速度。在 Colab 中解壓縮 zip 檔案也很容易，您只需要使用 Python 的 zipfile 库即可。
2. 使用 Google Drive API：如果您需要上傳大量的圖片，且每個圖片的大小都很大，建議使用 Google Drive API 進行上傳。使用 Google Drive API 可以實現快速且穩定的大容量文件上傳，不會受到 Colab 單次上傳大小的限制。
3. 更換網絡環境：如果您的網絡環境速度較慢，可以嘗試切換網絡環境。您可以使用 Colab 提供的免費 VPN 服務，或者使用付費 VPN 服務，以加速上傳速度。
4. 使用 Colab Pro：如果您經常使用 Colab，建議升級到 Colab Pro 版本。Colab Pro 可以提供更高速的網絡帶寬和更強大的硬體配置，從而可以更快地上傳圖片。

![Untitled](%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%20820418323bf14b2db51f4e1b9aab5aca/Untitled.png)

[檔名](%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%20820418323bf14b2db51f4e1b9aab5aca/%E6%AA%94%E5%90%8D%20061642dfb98b4971baacd8d4f57ae0d8.md)

| 參數 | 選項 | 影響 | 比較 |
| --- | --- | --- | --- |
| 神經元數量 | 16, 32, 64, 128, 256, 512 | 容量 | 小神經元數量導致欠擬合，大神經元數量導致過擬合 |
| 批次大小 | 8, 16, 32, 64, 128, 256 | 優化速度 | 小批次大小收斂速度快但準確率低，大批次大小準確率高但收斂速度慢 |
| 優化器 | SGD, Momentum, RMSprop, Adam | 收斂速度和準確率 | SGD在局部極小值處易陷入振盪，Momentum可以平滑優化過程，RMSprop在不同維度上設定不同的學習率可以提高效率，Adam同時具備優化速度和準確率優秀的特點 |
| 激活函數 | ReLU, LeakyReLU, ELU | 神經元輸出的非線性 | ReLU具有快速收斂和避免梯度消失的特點，但存在死亡神經元問題，LeakyReLU和ELU可以有效解決此問題 |
| 學習率 | 0.001, 0.01, 0.1 | 收斂速度和準確率 | 學習率過大容易使模型發生震盪，學習率過小收斂速度慢，通常選擇初始學習率較小，然後逐漸遞減的方式來訓練模型 |
| 正規化 | L1, L2 | 模型的泛化能力 | L1和L2都可以減小模型的過擬合，L1會讓權重變得稀疏，L2則會使權重縮小 |
| Dropout | 0.1, 0.2, 0.3, 0.4, 0.5 | 模型的泛化能力 | Dropout可以減少模型的過擬合，通過隨機丟棄一定比例的神經元來降低模型的複雜度 |
- 如果需要加速卷積過程，可以增加Stride的值，但是這樣會降低卷積神經網絡的特徵提取能力。
- Stride的值和卷積核的大小、填充方式以及輸入特徵圖的大小都會對輸出特徵圖的尺寸產生影響，因此在設計卷積神經網絡時需要綜合考慮這些因素。
1. 卷積層(Convolutional layer)：卷積層是卷積神經網路(CNN)的核心組成部分。它將輸入數據與卷積核進行卷積運算，以提取圖像或視頻中的特徵。卷積層通常由多個濾波器組成，每個濾波器可以檢測輸入數據的不同特徵。
2. 池化層(Pooling layer)：池化層通常跟在卷積層之後，通過對卷積輸出進行降採樣，減小特徵圖的大小，以減少計算量並且防止過擬合。池化層可以是最大池化、平均池化等不同類型。
3. 激活層(Activation layer)：激活層通常被插入到卷積層或者完全連接層之間，用於引入非線性變換，增加模型的表達能力。常見的激活函數有ReLU、Sigmoid、Tanh、LeakyReLU等。
4. 平坦層(Flatten layer)：平坦層將多維輸入數據展平成一維向量，以便輸入到完全連接層。
5. 完全連接層(Fully connected layer)：完全連接層是一種標準的神經網路層，每個神經元都連接到上一層的所有神經元。它通常用於對高層特徵的分類或者回歸任務。
- 對於輸入數據維度較小的問題，MLP通常比CNN更為適合，而對於輸入數據維度較大的問題，CNN通常比MLP更為適合。

one-hot編碼是一種將分類變數轉換成為二進制數值的編碼方式，對於每一個類別，都用一個二進制數值表示。例如，假設有三個類別，分別為"A"、"B"和"C"，那麼它們的one-hot編碼可以表示為：

A: 1 0 0
B: 0 1 0
C: 0 0 1

```python
from keras.utils import to_categorical

# 定義分類變數
y = [0, 1, 2, 1, 0, 2]

# 將分類變數轉換成為one-hot編碼
y_one_hot = to_categorical(y, num_classes=3)

print(y_one_hot)
```

model.compile 主要完成損失函數和優化器的配置

model.fit 用來訓練模型，其中參數verbose用來控制是否要記錄
訓練歷程，validation_split 是指切割訓練資料部分比例做為驗證
（validation）用。

在 Keras 中，model.evaluate 函數可用來測試模型的效率。其中
的參數 x_test 和 y_test 分別是測試資料集和標記。會回傳損失值和準確率。

model.save_weights 函數
將訓練好的模型的參數記錄下來，供未來預測使用

model.load_weights 函數從模型檔案中
載入模型參數